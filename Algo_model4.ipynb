{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, RandomizedSearchCV\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  algorithm                                          plaintext  \\\n",
      "0       AES  The volunteerism is a key component of communi...   \n",
      "1       AES  +\"f&R*~?GE3%-'}}i5bMx\"IB:dqN0?2/R)sHWm;\\.:SP1$...   \n",
      "2       AES  The educational technology is a key component ...   \n",
      "3       AES                        [GmcvmxtqF4}`}wOs NyXORrP{*   \n",
      "4       AES  The encryption is a key component of global po...   \n",
      "\n",
      "                                                 key  \\\n",
      "0  06f50db57c46117664333a82aa4628adf24baf21367d26...   \n",
      "1  5bbff7147513d5e3624560a71214653e3ebe1b330c41e1...   \n",
      "2  e229117d280cafcec62d4cbf6555bdee64da661d5226c1...   \n",
      "3  74c9b7ebe8cc4cf50c99c34ede237bf48cf3813c3f9569...   \n",
      "4  2226799dab3df3b994d8ee4f86398ba251c99c25ac4b6a...   \n",
      "\n",
      "                                 iv  \\\n",
      "0  8855be909cbf4c1cf3f646fcfe0bb375   \n",
      "1  bfa2fe6369565e48493aecfe3c625f78   \n",
      "2  d95b59ff2e2911759b468342e537eb26   \n",
      "3  237b47f8047ba7480f365e62b16487f6   \n",
      "4  b7c4f3f628754f520f27655145ed4d7c   \n",
      "\n",
      "                                   encrypted_message  \n",
      "0  d3e0244d9826020568bcfae4fafe24c6c86c4099ea54e2...  \n",
      "1  d21be4cd782e874cdc0f7a3c774f167ffa28dd97ef6ea3...  \n",
      "2  cbfe895c730757e6280a4d0f1b21fe8f5e0340598e1218...  \n",
      "3  e670725a4301eb41262e8eef5527161c41fc068eb9c6ff...  \n",
      "4  b4f5b0c67de3dca44ba58c17e58de75376b0ec130e25c8...  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('C://Users//Jayashrinidhi V//OneDrive//Documents//VScode//AlgoMaster//encrypted_messages_dataset12.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models\n",
    "base_models = [\n",
    "    ('logreg', LogisticRegression(max_iter=1000)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('decision_tree', DecisionTreeClassifier()),\n",
    "    ('random_forest', RandomForestClassifier()),\n",
    "    ('gbm', GradientBoostingClassifier()),\n",
    "    ('xgboost', xgb.XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)),\n",
    "    ('catboost', CatBoostClassifier(silent=True)),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('naive_bayes', MultinomialNB())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for tuning\n",
    "param_grids = {\n",
    "    'logreg': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'],  # Remove 'elasticnet' if not using 'saga'\n",
    "        'solver': ['liblinear', 'saga'],  # Only use 'saga' for 'elasticnet' penalty\n",
    "    },\n",
    "    'svc': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 5, 10],\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False],\n",
    "    },\n",
    "    'gbm': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    },\n",
    "    'catboost': {\n",
    "        'iterations': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'depth': [3, 5, 7],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7],\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    },\n",
    "    'naive_bayes': {\n",
    "        'alpha': [0.01, 0.1, 1, 10],\n",
    "        'fit_prior': [True, False],\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "data['algorithm_encoded'] = le.fit_transform(data['algorithm'])\n",
    "\n",
    "# Define features and target\n",
    "X = data['encrypted_message']\n",
    "y = data['algorithm_encoded']\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_features = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split dataset for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "logreg_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "logreg_grid_search = GridSearchCV(estimator=logreg, param_grid=logreg_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "logreg_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and parameters\n",
    "best_logreg = logreg_grid_search.best_estimator_\n",
    "print(f\"Best parameters for Logistic Regression: {logreg_grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.joblib']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "# Save the trained model\n",
    "dump(logreg, 'logistic_regression_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26  0]\n",
      " [ 0 19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26  0]\n",
      " [ 0 19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from joblib import dump, load\n",
    "\n",
    "# Define parameter grid for Logistic Regression with stronger regularization\n",
    "logreg_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1],  # Stronger regularization\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [50]\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "logreg_grid_search = GridSearchCV(estimator=logreg, param_grid=logreg_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "logreg_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and parameters\n",
    "best_logreg = logreg_grid_search.best_estimator_\n",
    "print(f\"Best parameters for Logistic Regression: {logreg_grid_search.best_params_}\")\n",
    "\n",
    "# Save the trained model\n",
    "dump(best_logreg, 'logistic_regression_model_regularized.joblib')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_logreg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVC: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for SVC\n",
    "svc_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Initialize SVC model\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "svc_grid_search = GridSearchCV(estimator=svc, param_grid=svc_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "svc_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and parameters\n",
    "best_svc = svc_grid_search.best_estimator_\n",
    "print(f\"Best parameters for SVC: {svc_grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Decision Tree: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Decision Tree\n",
    "decision_tree_param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Decision Tree model\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Perform GridSearchCV\n",
    "decision_tree_grid_search = GridSearchCV(estimator=decision_tree, param_grid=decision_tree_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "decision_tree_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and parameters\n",
    "best_decision_tree = decision_tree_grid_search.best_estimator_\n",
    "print(f\"Best parameters for Decision Tree: {decision_tree_grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "# Save the trained model to a file\n",
    "dump(decision_tree, 'decision_tree_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "# This will raise a NotFittedError if gbm is not fitted\n",
    "check_is_fitted(gbm, 'estimators_')\n",
    "# Assuming X_test is your test feature set\n",
    "y_pred = gbm_loaded.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report (includes precision, recall, F1-score)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        3DES       0.14      0.24      0.18        49\n",
      "         AES       0.17      0.21      0.19        56\n",
      "    Blowfish       0.12      0.09      0.10        66\n",
      "    ChaCha20       0.29      0.25      0.27        64\n",
      "         DES       0.35      0.22      0.27        65\n",
      "\n",
      "    accuracy                           0.20       300\n",
      "   macro avg       0.21      0.20      0.20       300\n",
      "weighted avg       0.22      0.20      0.20       300\n",
      "\n",
      "[[12  9 13 11  4]\n",
      " [12 12 14  9  9]\n",
      " [23 18  6 14  5]\n",
      " [15 17  8 16  8]\n",
      " [22 16  8  5 14]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "random_forest_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest model\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "# Perform GridSearchCV\n",
    "random_forest_grid_search = GridSearchCV(estimator=random_forest, param_grid=random_forest_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "random_forest_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and parameters\n",
    "best_random_forest = random_forest_grid_search.best_estimator_\n",
    "print(f\"Best parameters for Random Forest: {random_forest_grid_search.best_params_}\")\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Convert encrypted message from hexadecimal to a format usable for ML models\n",
    "def hex_to_bytes(hex_string):\n",
    "    return bytes.fromhex(hex_string)\n",
    "\n",
    "data['encrypted_message_bytes'] = data['encrypted_message'].apply(hex_to_bytes)\n",
    "\n",
    "# Create features (e.g., byte frequency histogram)\n",
    "def create_features(byte_string):\n",
    "    histogram = np.zeros(256, dtype=int)\n",
    "    for byte in byte_string:\n",
    "        histogram[byte] += 1\n",
    "    return histogram\n",
    "\n",
    "X = np.array([create_features(message) for message in data['encrypted_message_bytes']])\n",
    "y = data['algorithm']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this runs for 40 mins DO NOT RUN MORE THAN ONCE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Gradient Boosting\n",
    "gbm_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Gradient Boosting model\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "# Perform GridSearchCV\n",
    "gbm_grid_search = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "gbm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and parameters\n",
    "best_gbm = gbm_grid_search.best_estimator_\n",
    "print(f\"Best parameters for Gradient Boosting: {gbm_grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gradient_boosting_model.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "# Save the trained model to a file\n",
    "dump(gbm, 'gradient_boosting_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from joblib import dump, load\n",
    "\n",
    "# Instantiate and fit the model\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train, y_train)  # Train the model on your training data\n",
    "\n",
    "# Save the trained model\n",
    "dump(gbm, 'gradient_boosting_model.joblib')\n",
    "\n",
    "# Load the model\n",
    "gbm_loaded = load('gradient_boosting_model.joblib')\n",
    "\n",
    "# Now make predictions with the loaded model\n",
    "y_pred = gbm_loaded.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1800\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        3DES       0.17      0.22      0.19        49\n",
      "         AES       0.16      0.20      0.18        56\n",
      "    Blowfish       0.21      0.17      0.19        66\n",
      "    ChaCha20       0.22      0.23      0.23        64\n",
      "         DES       0.13      0.09      0.11        65\n",
      "\n",
      "    accuracy                           0.18       300\n",
      "   macro avg       0.18      0.18      0.18       300\n",
      "weighted avg       0.18      0.18      0.18       300\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11  8  7 13 10]\n",
      " [17 11  6 14  8]\n",
      " [13 14 11 15 13]\n",
      " [12 16 11 15 10]\n",
      " [13 19 17 10  6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "# This will raise a NotFittedError if gbm is not fitted\n",
    "check_is_fitted(gbm, 'estimators_')\n",
    "# Assuming X_test is your test feature set\n",
    "y_pred = gbm_loaded.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report (includes precision, recall, F1-score)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 720 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n720 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got ['3DES' 'AES' 'Blowfish' 'ChaCha20' 'DES']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Perform GridSearchCV\u001b[39;00m\n\u001b[0;32m     17\u001b[0m xgboost_grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgboost, param_grid\u001b[38;5;241m=\u001b[39mxgboost_param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mxgboost_grid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Best estimator and parameters\u001b[39;00m\n\u001b[0;32m     21\u001b[0m best_xgboost \u001b[38;5;241m=\u001b[39m xgboost_grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:995\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    993\u001b[0m     )\n\u001b[1;32m--> 995\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 720 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n720 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got ['3DES' 'AES' 'Blowfish' 'ChaCha20' 'DES']\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for XGBoost\n",
    "xgboost_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgboost = xgb.XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "xgboost_grid_search = GridSearchCV(estimator=xgboost, param_grid=xgboost_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "xgboost_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and parameters\n",
    "best_xgboost = xgboost_grid_search.best_estimator_\n",
    "print(f\"Best parameters for XGBoost: {xgboost_grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for CatBoost\n",
    "catboost_param_grid = {\n",
    "    'iterations': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "# Initialize CatBoost model\n",
    "catboost = CatBoostClassifier(silent=True)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "catboost_grid_search = GridSearchCV(estimator=catboost, param_grid=catboost_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "catboost_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and parameters\n",
    "best_catboost = catboost_grid_search.best_estimator_\n",
    "print(f\"Best parameters for CatBoost: {catboost_grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for KNN\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Initialize KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform GridSearchCV\n",
    "knn_grid_search = GridSearchCV(estimator=knn, param_grid=knn_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "knn_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and parameters\n",
    "best_knn = knn_grid_search.best_estimator_\n",
    "print(f\"Best parameters for KNN: {knn_grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Naive Bayes\n",
    "naive_bayes_param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize Naive Bayes model\n",
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "# Perform GridSearchCV\n",
    "naive_bayes_grid_search = GridSearchCV(estimator=naive_bayes, param_grid=naive_bayes_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "naive_bayes_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and parameters\n",
    "best_naive_bayes = naive_bayes_grid_search.best_estimator_\n",
    "print(f\"Best parameters for Naive Bayes: {naive_bayes_grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tuned models\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Use the hyperparameter-tuned models\n",
    "tuned_models = [\n",
    "    ('logreg', LogisticRegression(C=0.01, penalty='l1', solver='liblinear', max_iter=1000)),\n",
    "    ('svc', SVC(C=0.1, gamma='scale', kernel='linear', probability=True)),\n",
    "    ('decision_tree', DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_split=10)),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=200, max_depth=5, min_samples_split=10, random_state=42)),\n",
    "    ('gbm', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)),\n",
    "    ('xgboost', xgb.XGBClassifier(eval_metric='mlogloss', n_estimators=100, learning_rate=0.1, max_depth=3)),\n",
    "    ('catboost', CatBoostClassifier(silent=True, iterations=100, learning_rate=0.1, depth=3)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('naive_bayes', MultinomialNB(alpha=0.1))\n",
    "]\n",
    "\n",
    "# Create the voting classifier\n",
    "voting_clf = VotingClassifier(estimators=tuned_models, voting='soft')\n",
    "\n",
    "# Fit the voting classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the voting classifier\n",
    "voting_accuracy = voting_clf.score(X_test, y_test)\n",
    "print(f'Voting Classifier Accuracy: {voting_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking_clf = StackingClassifier(estimators=tuned_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Fit the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the stacking classifier\n",
    "stacking_accuracy = stacking_clf.score(X_test, y_test)\n",
    "print(f'Stacking Classifier Accuracy: {stacking_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Bagging using DecisionTreeClassifier\n",
    "bagging_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_split=10), n_estimators=50, random_state=42)\n",
    "\n",
    "# Fit the bagging classifier\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the bagging classifier\n",
    "bagging_accuracy = bagging_clf.score(X_test, y_test)\n",
    "print(f'Bagging Classifier Accuracy: {bagging_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Gradient Boosting\n",
    "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "gbm.fit(X_train, y_train)\n",
    "gbm_accuracy = gbm.score(X_test, y_test)\n",
    "print(f'Gradient Boosting Classifier Accuracy: {gbm_accuracy}')\n",
    "\n",
    "# XGBoost\n",
    "xgb_clf = xgb.XGBClassifier(eval_metric='mlogloss', n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "xgb_accuracy = xgb_clf.score(X_test, y_test)\n",
    "print(f'XGBoost Classifier Accuracy: {xgb_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Voting, Stacking, Bag & Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Define function to evaluate and compare models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return accuracy\n",
    "\n",
    "# Voting Classifier\n",
    "print(\"Evaluating Voting Classifier...\")\n",
    "voting_accuracy = evaluate_model(voting_clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Stacking Classifier\n",
    "print(\"\\nEvaluating Stacking Classifier...\")\n",
    "stacking_accuracy = evaluate_model(stacking_clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Bagging and Boosting Classifiers\n",
    "print(\"\\nEvaluating Bagging/Boosting Classifiers...\")\n",
    "bagging_boosting_accuracies = []\n",
    "for model_name, model in bagging_boosting_classifiers.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    accuracy = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "    bagging_boosting_accuracies.append((model_name, accuracy))\n",
    "\n",
    "# Comparison Summary\n",
    "print(\"\\nComparison Summary:\")\n",
    "print(f\"Voting Classifier Accuracy: {voting_accuracy:.4f}\")\n",
    "print(f\"Stacking Classifier Accuracy: {stacking_accuracy:.4f}\")\n",
    "for model_name, accuracy in bagging_boosting_accuracies:\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Compute Average Accuracy for Bagging/Boosting\n",
    "average_bagging_boosting_accuracy = np.mean([acc[1] for acc in bagging_boosting_accuracies])\n",
    "print(f\"Average Bagging/Boosting Accuracy: {average_bagging_boosting_accuracy:.4f}\")\n",
    "\n",
    "# Additional Metrics (optional)\n",
    "print(\"\\nAdditional Metrics:\")\n",
    "print(\"ROC AUC Score for Voting Classifier:\", roc_auc_score(y_test, voting_clf.predict_proba(X_test), multi_class='ovr'))\n",
    "print(\"ROC AUC Score for Stacking Classifier:\", roc_auc_score(y_test, stacking_clf.predict_proba(X_test), multi_class='ovr'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
