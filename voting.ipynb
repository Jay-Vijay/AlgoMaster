{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  algorithm                                          plaintext  \\\n",
      "0       AES  The volunteerism is a key component of communi...   \n",
      "1       AES  +\"f&R*~?GE3%-'}}i5bMx\"IB:dqN0?2/R)sHWm;\\.:SP1$...   \n",
      "2       AES  The educational technology is a key component ...   \n",
      "3       AES                        [GmcvmxtqF4}`}wOs NyXORrP{*   \n",
      "4       AES  The encryption is a key component of global po...   \n",
      "\n",
      "                                                 key  \\\n",
      "0  06f50db57c46117664333a82aa4628adf24baf21367d26...   \n",
      "1  5bbff7147513d5e3624560a71214653e3ebe1b330c41e1...   \n",
      "2  e229117d280cafcec62d4cbf6555bdee64da661d5226c1...   \n",
      "3  74c9b7ebe8cc4cf50c99c34ede237bf48cf3813c3f9569...   \n",
      "4  2226799dab3df3b994d8ee4f86398ba251c99c25ac4b6a...   \n",
      "\n",
      "                                 iv  \\\n",
      "0  8855be909cbf4c1cf3f646fcfe0bb375   \n",
      "1  bfa2fe6369565e48493aecfe3c625f78   \n",
      "2  d95b59ff2e2911759b468342e537eb26   \n",
      "3  237b47f8047ba7480f365e62b16487f6   \n",
      "4  b7c4f3f628754f520f27655145ed4d7c   \n",
      "\n",
      "                                   encrypted_message  \n",
      "0  d3e0244d9826020568bcfae4fafe24c6c86c4099ea54e2...  \n",
      "1  d21be4cd782e874cdc0f7a3c774f167ffa28dd97ef6ea3...  \n",
      "2  cbfe895c730757e6280a4d0f1b21fe8f5e0340598e1218...  \n",
      "3  e670725a4301eb41262e8eef5527161c41fc068eb9c6ff...  \n",
      "4  b4f5b0c67de3dca44ba58c17e58de75376b0ec130e25c8...  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('C://Users//Jayashrinidhi V//OneDrive//Documents//VScode//AlgoMaster//encrypted_messages_dataset12.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "data['algorithm_encoded'] = le.fit_transform(data['algorithm'])\n",
    "\n",
    "# Define features and target\n",
    "X = data['encrypted_message']\n",
    "y = data['algorithm_encoded']\n",
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_features = vectorizer.fit_transform(X)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('logreg', LogisticRegression(max_iter=1000)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('decision_tree', DecisionTreeClassifier()),\n",
    "    ('random_forest', RandomForestClassifier()),\n",
    "    ('gbm', GradientBoostingClassifier()),\n",
    "    ('xgboost', xgb.XGBClassifier(eval_metric='mlogloss')),\n",
    "    ('catboost', CatBoostClassifier(silent=True)),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('naive_bayes', MultinomialNB())\n",
    "]\n",
    "\n",
    "# Define meta-model for stacking\n",
    "meta_model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "rf_grid_search = GridSearchCV(estimator=rf_clf, param_grid=rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best parameters for Random Forest:\", rf_grid_search.best_params_)\n",
    "best_rf_model = rf_grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for KNN: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for KNN\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "knn_grid_search = GridSearchCV(estimator=knn_clf, param_grid=knn_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "knn_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best parameters for KNN:\", knn_grid_search.best_params_)\n",
    "best_knn_model = knn_grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for XGBoost: {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:01:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "xgb_clf = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_clf, param_grid=xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best parameters for XGBoost:\", xgb_grid_search.best_params_)\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:01:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:01:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:01:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:01:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CV Accuracy: 0.20916666666666667\n",
      "KNN CV Accuracy: 0.195\n",
      "XGBoost CV Accuracy: 0.20916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:01:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "rf_cv_scores = cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "knn_cv_scores = cross_val_score(best_knn_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "xgb_cv_scores = cross_val_score(best_xgb_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Random Forest CV Accuracy:\", rf_cv_scores.mean())\n",
    "print(\"KNN CV Accuracy:\", knn_cv_scores.mean())\n",
    "print(\"XGBoost CV Accuracy:\", xgb_cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with class weights Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      1.00      0.28        49\n",
      "           1       0.00      0.00      0.00        56\n",
      "           2       0.00      0.00      0.00        66\n",
      "           3       0.00      0.00      0.00        64\n",
      "           4       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.16       300\n",
      "   macro avg       0.03      0.20      0.06       300\n",
      "weighted avg       0.03      0.16      0.05       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Example for RandomForest with class weights\n",
    "rf_clf_with_weights = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Fit the model\n",
    "rf_clf_with_weights.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf_weights = rf_clf_with_weights.predict(X_test)\n",
    "print(\"RandomForest with class weights Report:\\n\", classification_report(y_test, y_pred_rf_weights))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
