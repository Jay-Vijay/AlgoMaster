{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  algorithm                                          plaintext  \\\n",
      "0       AES  :L0@86._C.,y@}tkOz\"Pfjrd.:_~<V##~;X!)&2p]lfng2...   \n",
      "1       AES                               qn3=6B)oqGX585a_[4IU   \n",
      "2       AES  In the world of human rights, data integrity p...   \n",
      "3       AES  0/xe+$jEcc:Lgm<mu&yz, Q|Q@QdjH ?eUx&_Z_xw._-%p...   \n",
      "4       AES  2Kdg~|%lLG~b{7ggU^Y<D|HcQ'w0dyQF7[1HQU%4F/D`@4...   \n",
      "\n",
      "                                                 key  \\\n",
      "0  b6928ad6150f1fdb90ceca40c3b41c0e256a2108852a2a...   \n",
      "1  58961e57dd0706c30a78f4db788a3ca374361f57e50362...   \n",
      "2  9b894ca23e60cfddacda7fbff2448ac183377f0e52bd36...   \n",
      "3  5b3bad22934a6e6b4568d4455fe521941fa886a1df36f9...   \n",
      "4  4dd9fc66a4e54d43597291ceff00ed73ab56356b2d13d1...   \n",
      "\n",
      "                                 iv  \\\n",
      "0  fcadfe9253f711ea3e0d42fe96e7be09   \n",
      "1  696dfe1c1abb2374f3739af173a825de   \n",
      "2  3b074c00bb75cb36bd0c13f167452630   \n",
      "3  c767572137d5a8e56d6ff12ee1ddfe58   \n",
      "4  b96a2a1503677b500d278d54e2bab111   \n",
      "\n",
      "                                   encrypted_message  \n",
      "0  d931f2f261d67c0c467e68e94eb023ec2337a591773f9e...  \n",
      "1  9d14adcb96c7130e38b152aa5039092748fbcab6efc52a...  \n",
      "2  794c8f4ed3e2046cc882d2e2888a71e8c19046840c9a02...  \n",
      "3  196171cb3b6bb93d3e933a17bde255e0754b4c3dac9ab1...  \n",
      "4  f0afb0add161960b4b497437330cc8dddc1d12b0c56e04...  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('C://Users//Jayashrinidhi V//OneDrive//Documents//VScode//AlgoMaster//data_700_5.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm            0\n",
      "plaintext            0\n",
      "key                  0\n",
      "iv                   0\n",
      "encrypted_message    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(data['algorithm'])\n",
    "\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 2))  # Character-level 1-2 gram analysis\n",
    "plaintext_features = vectorizer.fit_transform(data['plaintext'])\n",
    "key_features = vectorizer.transform(data['key'])\n",
    "iv_features = vectorizer.transform(data['iv'])\n",
    "encrypted_message_features = vectorizer.transform(data['encrypted_message'])\n",
    "\n",
    "# Convert sparse matrices to dense arrays\n",
    "plaintext_features = plaintext_features.toarray()\n",
    "key_features = key_features.toarray()\n",
    "iv_features = iv_features.toarray()\n",
    "encrypted_message_features = encrypted_message_features.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all features\n",
    "X = np.hstack([\n",
    "    plaintext_features,\n",
    "    key_features,\n",
    "    iv_features,\n",
    "    encrypted_message_features\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target variable for multi-class classification\n",
    "y_encoded = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create the neural network model\n",
    "model = Sequential()\n",
    "#model.add(Dense(units=32, activation='relu', input_dim=X_train.shape[1]))\n",
    "#model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=16, activation='relu', input_dim=X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(units=y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayashrinidhi V\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the learning rate\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Create the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model with the learning rate\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=16, activation='softmax', input_dim=X_train.shape[1]))\n",
    "#model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model with the learning rate\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2250 - loss: 1.5892 - val_accuracy: 0.5000 - val_loss: 1.4795\n",
      "Epoch 2/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6962 - loss: 1.3419 - val_accuracy: 0.5679 - val_loss: 1.3779\n",
      "Epoch 3/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 1.1891 - val_accuracy: 0.5875 - val_loss: 1.3168\n",
      "Epoch 4/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 1.0753 - val_accuracy: 0.6179 - val_loss: 1.2742\n",
      "Epoch 5/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8865 - loss: 0.9791 - val_accuracy: 0.6214 - val_loss: 1.2250\n",
      "Epoch 6/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8988 - loss: 0.9021 - val_accuracy: 0.6214 - val_loss: 1.1802\n",
      "Epoch 7/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9136 - loss: 0.8238 - val_accuracy: 0.6393 - val_loss: 1.1354\n",
      "Epoch 8/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.7655 - val_accuracy: 0.6607 - val_loss: 1.1025\n",
      "Epoch 9/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9478 - loss: 0.7024 - val_accuracy: 0.6696 - val_loss: 1.0819\n",
      "Epoch 10/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.6393 - val_accuracy: 0.6696 - val_loss: 1.0595\n",
      "Epoch 11/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.5847 - val_accuracy: 0.6750 - val_loss: 1.0358\n",
      "Epoch 12/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9707 - loss: 0.5340 - val_accuracy: 0.6661 - val_loss: 1.0218\n",
      "Epoch 13/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.4903 - val_accuracy: 0.6696 - val_loss: 1.0027\n",
      "Epoch 14/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.4492 - val_accuracy: 0.6714 - val_loss: 0.9949\n",
      "Epoch 15/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.4184 - val_accuracy: 0.6696 - val_loss: 0.9889\n",
      "Epoch 16/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.3864 - val_accuracy: 0.6554 - val_loss: 0.9964\n",
      "Epoch 17/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9885 - loss: 0.3518 - val_accuracy: 0.6589 - val_loss: 1.0104\n",
      "Epoch 18/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.3311 - val_accuracy: 0.6464 - val_loss: 1.0126\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "#history = model.fit(X_train, y_train, epochs=30, batch_size=8, validation_split=0.2, verbose=1)\n",
    "\"\"\"#\n",
    " for 60\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=20,batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 'neural_network_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a file\n",
    "model.save('neural_network_model.h5')\n",
    "print(\"Model saved to 'neural_network_model.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6571\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.25      0.32       138\n",
      "           1       0.96      0.84      0.89       167\n",
      "           2       0.88      0.88      0.88       120\n",
      "           3       0.76      0.77      0.76       137\n",
      "           4       0.35      0.54      0.43       138\n",
      "\n",
      "    accuracy                           0.66       700\n",
      "   macro avg       0.67      0.66      0.66       700\n",
      "weighted avg       0.68      0.66      0.66       700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 35   0   5  14  84]\n",
      " [  0 140   0  10  17]\n",
      " [  2   0 105   0  13]\n",
      " [  6   2   0 105  24]\n",
      " [ 39   4  10  10  75]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred_classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
